Filesystems usage for user sawall ( uid 646284814 ):-------------------------------------------------------------------------------------Directory                           Used   Limit   Used,%         Files     Limit-------------------------------------------------------------------------------------/home/sawall                       3.6GB    15GB    23.8%        20,034   100,000/data/sawall                       132GB   200GB    65.7%     1,094,826          /scratch/sawall                    147GB    20TB     0.7%         5,523          /shares/tanadini-lang.physik.uzh      0B    10TB     0.0%             2          -------------------------------------------------------------------------------------Files on /scratch may be purged after 30 days.See https://docs.s3it.uzh.ch/cluster/dataRunning on host : u20-cva0ts0-508Starting 3DPix2Pix Overfit on 1ABA001Tue Jul 29 13:43:40 2025       +-----------------------------------------------------------------------------------------+| NVIDIA-SMI 560.35.05              Driver Version: 560.35.05      CUDA Version: 12.6     ||-----------------------------------------+------------------------+----------------------+| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC || Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. ||                                         |                        |               MIG M. ||=========================================+========================+======================||   0  Tesla T4                       Off |   00000000:00:07.0 Off |                    0 || N/A   31C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default ||                                         |                        |                  N/A |+-----------------------------------------+------------------------+----------------------+                                                                                         +-----------------------------------------------------------------------------------------+| Processes:                                                                              ||  GPU   GI   CI        PID   Type   Process name                              GPU Memory ||        ID   ID                                                               Usage      ||=========================================================================================||  No running processes found                                                             |+-----------------------------------------------------------------------------------------+/home/sawall/3D/train_4channel_256.py:115: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.  self.scaler = torch.cuda.amp.GradScaler()------------ Options -------------batchSize: 1beta1: 0.5checkpoints_dir: /home/sawall/scratch/checkpointscontinue_train: Falsedataroot: /home/sawall/scratch/latent_data/latent_scaled/HN/dataset_mode: unaligneddepthSize: 256display_freq: 100display_id: 1display_port: 8097display_single_pane_ncols: 0display_winsize: 256epoch_count: 1fineSize: 256gpu_ids: [0]identity: 0.0input_nc: 3isTrain: Truelambda_A: 10.0lambda_B: 10.0loadSize: 286lr: 0.0002max_dataset_size: infmodel: cycle_gannThreads: 2n_layers_D: 3name: experiment_namendf: 64ngf: 64niter: 100niter_decay: 100no_dropout: Falseno_flip: Falseno_html: Falseno_lsgan: Falsenorm: instanceoutput_nc: 3phase: trainpool_size: 50print_freq: 100resize_or_crop: resize_and_cropsave_epoch_freq: 5save_latest_freq: 5000serial_batches: Falsewhich_direction: AtoBwhich_epoch: latestwhich_model_netD: basicwhich_model_netG: unet_4channel_256-------------- End ----------------🔧 High-Resolution 4-Channel Training Configuration:   📊 Input channels: 4   📊 Output channels: 1   📊 Expected input shape: (4, 64, 256, 256)   📊 Expected output shape: (1, 64, 256, 256)   🏗️ Generator: unet_4channel_256   📁 Dataset mode: four_channel   ⚖️ L1 loss weight: 100.0   🎨 Perceptual loss weight: 1.0   🔧 Mixed precision: True   💾 Gradient checkpointing: True   📏 Image size: 256CustomDatasetDataLoader� Found 152 MR files and 143 CT files✅ Paired: 1HNA010_latent_mr✅ Paired: 1HNA012_latent_mr✅ Paired: 1HNA013_latent_mr✅ Paired: 1HNA014_latent_mr✅ Paired: 1HNA015_latent_mr✅ Paired: 1HNA018_latent_mr✅ Paired: 1HNA019_latent_mr✅ Paired: 1HNA021_latent_mr✅ Paired: 1HNA023_latent_mr✅ Paired: 1HNA025_latent_mr✅ Paired: 1HNA026_latent_mr✅ Paired: 1HNA028_latent_mr✅ Paired: 1HNA029_latent_mr✅ Paired: 1HNA030_latent_mr✅ Paired: 1HNA031_latent_mr✅ Paired: 1HNA032_latent_mr✅ Paired: 1HNA033_latent_mr✅ Paired: 1HNA034_latent_mr✅ Paired: 1HNA035_latent_mr✅ Paired: 1HNA036_latent_mr✅ Paired: 1HNA037_latent_mr✅ Paired: 1HNA038_latent_mr✅ Paired: 1HNA039_latent_mr✅ Paired: 1HNA040_latent_mr✅ Paired: 1HNA041_latent_mr✅ Paired: 1HNA042_latent_mr✅ Paired: 1HNA043_latent_mr✅ Paired: 1HNA045_latent_mr✅ Paired: 1HNA047_latent_mr✅ Paired: 1HNA048_latent_mr✅ Paired: 1HNA049_latent_mr✅ Paired: 1HNA051_latent_mr✅ Paired: 1HNA053_latent_mr✅ Paired: 1HNA056_latent_mr✅ Paired: 1HNA059_latent_mr✅ Paired: 1HNA060_latent_mr✅ Paired: 1HNA061_latent_mr✅ Paired: 1HNA066_latent_mr✅ Paired: 1HNA067_latent_mr✅ Paired: 1HNA068_latent_mr✅ Paired: 1HNA069_latent_mr✅ Paired: 1HNA071_latent_mr✅ Paired: 1HNA072_latent_mr✅ Paired: 1HNA077_latent_mr✅ Paired: 1HNA082_latent_mr✅ Paired: 1HNA084_latent_mr✅ Paired: 1HNA085_latent_mr✅ Paired: 1HNA086_latent_mr✅ Paired: 1HNA089_latent_mr✅ Paired: 1HNA090_latent_mr✅ Paired: 1HNA091_latent_mr✅ Paired: 1HNA093_latent_mr✅ Paired: 1HNA095_latent_mr✅ Paired: 1HNA096_latent_mr✅ Paired: 1HNA097_latent_mr✅ Paired: 1HNA098_latent_mr✅ Paired: 1HNA099_latent_mr✅ Paired: 1HNA100_latent_mr✅ Paired: 1HNA102_latent_mr✅ Paired: 1HNA103_latent_mr✅ Paired: 1HNA104_latent_mr✅ Paired: 1HNA105_latent_mr✅ Paired: 1HNA106_latent_mr✅ Paired: 1HNA107_latent_mr✅ Paired: 1HNA108_latent_mr✅ Paired: 1HNA109_latent_mr✅ Paired: 1HNA110_latent_mr✅ Paired: 1HNA113_latent_mr❌ No CT match for 1HNA115_latent_mr.npz. Available CT files (truncated):    → ['1HNA015_latent_ct.npz', '1HNA061_latent_ct.npz', '1HNA041_latent_ct.npz', '1HNA060_latent_ct.npz', '1HNA051_latent_ct.npz'] ...✅ Paired: 1HNA116_latent_mr❌ No CT match for 1HNA117_latent_mr.npz. Available CT files (truncated):    → ['1HNA015_latent_ct.npz', '1HNA061_latent_ct.npz', '1HNA041_latent_ct.npz', '1HNA060_latent_ct.npz', '1HNA051_latent_ct.npz'] ...✅ Paired: 1HNA119_latent_mr✅ Paired: 1HNA120_latent_mr✅ Paired: 1HNA121_latent_mr✅ Paired: 1HNA124_latent_mr✅ Paired: 1HNA126_latent_mr✅ Paired: 1HNA129_latent_mr✅ Paired: 1HNA130_latent_mr✅ Paired: 1HNA132_latent_mr✅ Paired: 1HNA133_latent_mr✅ Paired: 1HNA135_latent_mr✅ Paired: 1HNA136_latent_mr✅ Paired: 1HNA138_latent_mr✅ Paired: 1HNA139_latent_mr✅ Paired: 1HNA141_latent_mr✅ Paired: 1HNA142_latent_mr✅ Paired: 1HNA143_latent_mr❌ No CT match for 1HNC001_latent_mr.npz. Available CT files (truncated):    → ['1HNA015_latent_ct.npz', '1HNA061_latent_ct.npz', '1HNA041_latent_ct.npz', '1HNA060_latent_ct.npz', '1HNA051_latent_ct.npz'] ...✅ Paired: 1HNC002_latent_mr✅ Paired: 1HNC003_latent_mr✅ Paired: 1HNC004_latent_mr✅ Paired: 1HNC005_latent_mr✅ Paired: 1HNC007_latent_mr✅ Paired: 1HNC008_latent_mr✅ Paired: 1HNC012_latent_mr❌ No CT match for 1HNC014_latent_mr.npz. Available CT files (truncated):    → ['1HNA015_latent_ct.npz', '1HNA061_latent_ct.npz', '1HNA041_latent_ct.npz', '1HNA060_latent_ct.npz', '1HNA051_latent_ct.npz'] ...✅ Paired: 1HNC017_latent_mr✅ Paired: 1HNC019_latent_mr❌ No CT match for 1HNC020_latent_mr.npz. Available CT files (truncated):    → ['1HNA015_latent_ct.npz', '1HNA061_latent_ct.npz', '1HNA041_latent_ct.npz', '1HNA060_latent_ct.npz', '1HNA051_latent_ct.npz'] ...✅ Paired: 1HNC021_latent_mr✅ Paired: 1HNC022_latent_mr✅ Paired: 1HNC023_latent_mr✅ Paired: 1HNC025_latent_mr✅ Paired: 1HNC029_latent_mr✅ Paired: 1HNC031_latent_mr❌ No CT match for 1HNC035_latent_mr.npz. Available CT files (truncated):    → ['1HNA015_latent_ct.npz', '1HNA061_latent_ct.npz', '1HNA041_latent_ct.npz', '1HNA060_latent_ct.npz', '1HNA051_latent_ct.npz'] ...✅ Paired: 1HNC036_latent_mr✅ Paired: 1HNC037_latent_mr✅ Paired: 1HNC038_latent_mr✅ Paired: 1HNC039_latent_mr✅ Paired: 1HNC040_latent_mr✅ Paired: 1HNC043_latent_mr✅ Paired: 1HNC045_latent_mr✅ Paired: 1HNC046_latent_mr✅ Paired: 1HNC050_latent_mr✅ Paired: 1HNC061_latent_mr✅ Paired: 1HNC066_latent_mr✅ Paired: 1HNC067_latent_mr✅ Paired: 1HNC068_latent_mr✅ Paired: 1HNC071_latent_mr❌ No CT match for 1HNC072_latent_mr.npz. Available CT files (truncated):    → ['1HNA015_latent_ct.npz', '1HNA061_latent_ct.npz', '1HNA041_latent_ct.npz', '1HNA060_latent_ct.npz', '1HNA051_latent_ct.npz'] ...✅ Paired: 1HNC073_latent_mr✅ Paired: 1HNC076_latent_mr✅ Paired: 1HNC082_latent_mr✅ Paired: 1HNC083_latent_mr✅ Paired: 1HNC084_latent_mr✅ Paired: 1HNC085_latent_mr❌ No CT match for 1HNC087_latent_mr.npz. Available CT files (truncated):    → ['1HNA015_latent_ct.npz', '1HNA061_latent_ct.npz', '1HNA041_latent_ct.npz', '1HNA060_latent_ct.npz', '1HNA051_latent_ct.npz'] ...✅ Paired: 1HNC088_latent_mr✅ Paired: 1HNC094_latent_mr✅ Paired: 1HNC098_latent_mr✅ Paired: 1HNC099_latent_mr✅ Paired: 1HNC101_latent_mr✅ Paired: 1HNC102_latent_mr✅ Paired: 1HNC103_latent_mr✅ Paired: 1HNC104_latent_mr✅ Paired: 1HNC105_latent_mr✅ Paired: 1HNC107_latent_mr✅ Paired: 1HNC109_latent_mr✅ Paired: 1HNC110_latent_mr✅ Paired: 1HNC111_latent_mr✅ Paired: 1HNC112_latent_mr✅ Paired: 1HNC114_latent_mr❌ No CT match for 1HNC117_latent_mr.npz. Available CT files (truncated):    → ['1HNA015_latent_ct.npz', '1HNA061_latent_ct.npz', '1HNA041_latent_ct.npz', '1HNA060_latent_ct.npz', '1HNA051_latent_ct.npz'] ...✅ Paired: 1HNC118_latent_mr✅ Paired: 1HNC120_latent_mr✅ Paired: 1HNC121_latent_mr✅ Paired: 1HNC124_latent_mr✅ Paired: 1HNC125_latent_mr✅ Paired: 1HNC127_latent_mr✅ Paired: 1HNC128_latent_mr✅ Paired: 1HNC130_latent_mr✅ 4-Channel dataset initialized:   Root: /home/sawall/scratch/latent_data/latent_scaled/HN/   Phase: train   Samples: 143   Augmentation: True   Expected MR shape: (4, 256, 256)   Expected CT shape: (256, 256)dataset [FourChannelDataset] was created📊 Dataset size: 143🏗️ Creating high-resolution 4-channel model...✅ Successfully imported 4-channel networks🚀 Starting high-resolution 4-channel training...   Epochs: 1 to 200   Batch size: 1   Learning rate: 0.0002   Input shape: (4, 64, 256, 256)   Output shape: (1, 64, 256, 256)   Architecture: unet_4channel_256Epoch 1:   0%|          | 0/143 [00:00<?, ?batch/s]/home/sawall/3D/train_4channel_256.py:161: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.  with torch.cuda.amp.autocast():Epoch 1:   0%|          | 0/143 [00:01<?, ?batch/s]Traceback (most recent call last):  File "/home/sawall/3D/train_4channel_256.py", line 475, in <module>    main()  File "/home/sawall/3D/train_4channel_256.py", line 444, in main    model.optimize_parameters()  File "/home/sawall/3D/train_4channel_256.py", line 255, in optimize_parameters    self.forward()  File "/home/sawall/3D/train_4channel_256.py", line 162, in forward    self.fake_B = self.netG(self.real_A)  File "/home/sawall/data/conda/envs/sCT/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl    return self._call_impl(*args, **kwargs)  File "/home/sawall/data/conda/envs/sCT/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl    return forward_call(*args, **kwargs)  File "/home/sawall/3D/models/networks_3d_4channel.py", line 239, in forward    return nn.parallel.data_parallel(lambda x: output, input, self.gpu_ids)  File "/home/sawall/data/conda/envs/sCT/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 263, in data_parallel    for t in chain(module.parameters(), module.buffers()):AttributeError: 'function' object has no attribute 'parameters'/var/lib/slurm/slurmd/job22676306/slurm_script: line 24: --name: command not found