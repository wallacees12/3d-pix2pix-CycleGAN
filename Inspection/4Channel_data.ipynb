{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62926721",
   "metadata": {},
   "source": [
    "# 4-Channel MR Latent Dataset Creation\n",
    "\n",
    "This notebook creates a dataset using all 4 channels from the MR latent representation for richer MR→CT synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbeaee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"📦 Libraries imported successfully\")\n",
    "print(f\"📍 Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d991cdc",
   "metadata": {},
   "source": [
    "## 📊 Load and Inspect Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4593217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your original data\n",
    "mr_latent_path = \"1ABA009_latent_mr.nii\"\n",
    "ct_path = \"CT_normalised_latent.mha\"\n",
    "\n",
    "print(\"🔍 Checking file existence:\")\n",
    "print(f\"MR latent file: {os.path.exists(mr_latent_path)} - {mr_latent_path}\")\n",
    "print(f\"CT file: {os.path.exists(ct_path)} - {ct_path}\")\n",
    "\n",
    "if not os.path.exists(mr_latent_path):\n",
    "    print(\"❌ MR latent file not found. Please check the path.\")\n",
    "if not os.path.exists(ct_path):\n",
    "    print(\"❌ CT file not found. Please check the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed8e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MR latent data (4D with 4 channels)\n",
    "mr_sitk = sitk.ReadImage(mr_latent_path)\n",
    "mr_array = sitk.GetArrayFromImage(mr_sitk)\n",
    "\n",
    "# Load the CT data \n",
    "ct_sitk = sitk.ReadImage(ct_path)\n",
    "ct_array = sitk.GetArrayFromImage(ct_sitk)\n",
    "\n",
    "print(\"📊 Data shapes:\")\n",
    "print(f\"MR latent shape: {mr_array.shape}\")\n",
    "print(f\"CT shape: {ct_array.shape}\")\n",
    "\n",
    "# Check if MR has channels\n",
    "if len(mr_array.shape) == 4:\n",
    "    print(f\"✅ MR data has {mr_array.shape[-1]} channels - Perfect for 4-channel processing!\")\n",
    "    print(f\"   Spatial dimensions: {mr_array.shape[:-1]}\")\n",
    "elif len(mr_array.shape) == 3:\n",
    "    print(f\"⚠️ MR data is 3D - might need to add channel dimension\")\n",
    "\n",
    "print(f\"📏 MR data range: [{np.min(mr_array):.3f}, {np.max(mr_array):.3f}]\")\n",
    "print(f\"📏 CT data range: [{np.min(ct_array):.3f}, {np.max(ct_array):.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b00abe1",
   "metadata": {},
   "source": [
    "## 🧩 Create 4-Channel Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26672ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = \"3D/datasets/all_channels\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"📁 Created output directory: {output_dir}\")\n",
    "\n",
    "# Define crop parameters (you can adjust these)\n",
    "# Using the full available data\n",
    "if len(mr_array.shape) == 4:\n",
    "    z_size, y_size, x_size, channels = mr_array.shape\n",
    "    crop_bounds = [0, z_size, 0, y_size, 0, x_size]\n",
    "else:\n",
    "    z_size, y_size, x_size = mr_array.shape\n",
    "    crop_bounds = [0, z_size, 0, y_size, 0, x_size]\n",
    "    channels = 1\n",
    "\n",
    "print(f\"📐 Data dimensions: {z_size}×{y_size}×{x_size} with {channels} channels\")\n",
    "print(f\"📋 Crop bounds: {crop_bounds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379d025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 4-channel MR data\n",
    "mr_filename = \"1HNA001_mr_all_channels.npz\"\n",
    "mr_output_path = os.path.join(output_dir, mr_filename)\n",
    "\n",
    "# Ensure we have 4D data (D, H, W, C)\n",
    "if len(mr_array.shape) == 4:\n",
    "    # Already has channels\n",
    "    mr_data_to_save = mr_array\n",
    "    print(f\"💾 Saving 4-channel MR data: {mr_array.shape}\")\n",
    "elif len(mr_array.shape) == 3:\n",
    "    # Add channel dimension - but this means we don't have 4 channels\n",
    "    mr_data_to_save = mr_array[..., np.newaxis]\n",
    "    print(f\"⚠️ Only 3D data available, adding single channel: {mr_data_to_save.shape}\")\n",
    "\n",
    "np.savez_compressed(mr_output_path, data=mr_data_to_save)\n",
    "print(f\"✅ Saved MR data to: {mr_output_path}\")\n",
    "\n",
    "# Save CT data\n",
    "ct_filename = \"1HNA001_ct.npz\"\n",
    "ct_output_path = os.path.join(output_dir, ct_filename)\n",
    "\n",
    "np.savez_compressed(ct_output_path, data=ct_array)\n",
    "print(f\"✅ Saved CT data to: {ct_output_path}\")\n",
    "\n",
    "# Verify saved data\n",
    "mr_loaded = np.load(mr_output_path)['data']\n",
    "ct_loaded = np.load(ct_output_path)['data']\n",
    "\n",
    "print(f\"\\n🔍 Verification:\")\n",
    "print(f\"MR saved shape: {mr_loaded.shape}\")\n",
    "print(f\"CT saved shape: {ct_loaded.shape}\")\n",
    "print(f\"MR channels available: {mr_loaded.shape[-1] if len(mr_loaded.shape) == 4 else 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbdaf73",
   "metadata": {},
   "source": [
    "## 📋 Create Dataset Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd74b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the crops.pkl file for the dataset\n",
    "sample_data = {\n",
    "    'name': '1HNA001',\n",
    "    'mr_path': mr_filename,\n",
    "    'ct_path': ct_filename,\n",
    "    'bounds': crop_bounds,\n",
    "    'channels': 'all_4_channels',\n",
    "    'channel_count': mr_loaded.shape[-1] if len(mr_loaded.shape) == 4 else 1\n",
    "}\n",
    "\n",
    "samples_list = [sample_data]\n",
    "\n",
    "# Save the metadata\n",
    "crops_pkl_path = os.path.join(output_dir, \"crops.pkl\")\n",
    "with open(crops_pkl_path, 'wb') as f:\n",
    "    pickle.dump(samples_list, f)\n",
    "\n",
    "print(f\"✅ Saved dataset metadata to: {crops_pkl_path}\")\n",
    "print(f\"📊 Sample data: {sample_data}\")\n",
    "\n",
    "# Verify the pickle file\n",
    "with open(crops_pkl_path, 'rb') as f:\n",
    "    loaded_samples = pickle.load(f)\n",
    "    \n",
    "print(f\"\\n🔍 Verification - loaded {len(loaded_samples)} samples:\")\n",
    "for i, sample in enumerate(loaded_samples):\n",
    "    print(f\"Sample {i}: {sample}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
