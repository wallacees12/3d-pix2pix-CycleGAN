{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62926721",
   "metadata": {},
   "source": [
    "# 4-Channel MR Latent Dataset Creation\n",
    "\n",
    "This notebook creates a dataset using all 4 channels from the MR latent representation for richer MR→CT synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bbeaee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Libraries imported successfully\n",
      "📍 Current directory: /Users/samwallace/Documents/sCT/Comparison Pix2Pix/3D/Inspection\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"📦 Libraries imported successfully\")\n",
    "print(f\"📍 Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d991cdc",
   "metadata": {},
   "source": [
    "## 📊 Load and Inspect Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4593217e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking file existence:\n",
      "MR latent file: True - /Users/samwallace/Documents/sCT/Comparison Pix2Pix/3D/datasets/overfit/1ABA009_latent_mr.nii\n",
      "CT file: True - /Users/samwallace/Documents/sCT/Comparison Pix2Pix/3D/datasets/overfit/CT_normalised_latent.mha\n"
     ]
    }
   ],
   "source": [
    "# Paths to your original data\n",
    "mr_latent_path = \"/Users/samwallace/Documents/sCT/Comparison Pix2Pix/3D/datasets/overfit/1ABA009_latent_mr.nii\"\n",
    "ct_path = \"/Users/samwallace/Documents/sCT/Comparison Pix2Pix/3D/datasets/overfit/CT_normalised_latent.mha\"\n",
    "\n",
    "print(\"🔍 Checking file existence:\")\n",
    "print(f\"MR latent file: {os.path.exists(mr_latent_path)} - {mr_latent_path}\")\n",
    "print(f\"CT file: {os.path.exists(ct_path)} - {ct_path}\")\n",
    "\n",
    "if not os.path.exists(mr_latent_path):\n",
    "    print(\"❌ MR latent file not found. Please check the path.\")\n",
    "if not os.path.exists(ct_path):\n",
    "    print(\"❌ CT file not found. Please check the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed8e15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Data shapes:\n",
      "MR latent shape: (32, 128, 128, 4)\n",
      "CT shape: (32, 128, 128)\n",
      "✅ MR data has 4 channels - Perfect for 4-channel processing!\n",
      "   Spatial dimensions: (32, 128, 128)\n",
      "📏 MR data range: [-4.169, 4.847]\n",
      "📏 CT data range: [-1.000, 1.000]\n"
     ]
    }
   ],
   "source": [
    "# Load the MR latent data (4D with 4 channels)\n",
    "mr_sitk = sitk.ReadImage(mr_latent_path)\n",
    "mr_array = sitk.GetArrayFromImage(mr_sitk)\n",
    "\n",
    "# Load the CT data \n",
    "ct_sitk = sitk.ReadImage(ct_path)\n",
    "ct_array = sitk.GetArrayFromImage(ct_sitk)\n",
    "\n",
    "print(\"📊 Data shapes:\")\n",
    "print(f\"MR latent shape: {mr_array.shape}\")\n",
    "print(f\"CT shape: {ct_array.shape}\")\n",
    "\n",
    "# Check if MR has channels\n",
    "if len(mr_array.shape) == 4:\n",
    "    print(f\"✅ MR data has {mr_array.shape[-1]} channels - Perfect for 4-channel processing!\")\n",
    "    print(f\"   Spatial dimensions: {mr_array.shape[:-1]}\")\n",
    "elif len(mr_array.shape) == 3:\n",
    "    print(f\"⚠️ MR data is 3D - might need to add channel dimension\")\n",
    "\n",
    "print(f\"📏 MR data range: [{np.min(mr_array):.3f}, {np.max(mr_array):.3f}]\")\n",
    "print(f\"📏 CT data range: [{np.min(ct_array):.3f}, {np.max(ct_array):.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b00abe1",
   "metadata": {},
   "source": [
    "## 🧩 Create 4-Channel Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26672ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Created output directory: ../datasets/all_channels\n",
      "📐 Data dimensions: 32×128×128 with 4 channels\n",
      "📋 Crop bounds: [0, 32, 0, 128, 0, 128]\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "output_dir = \"../datasets/all_channels\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"📁 Created output directory: {output_dir}\")\n",
    "\n",
    "# Define crop parameters (you can adjust these)\n",
    "# Using the full available data\n",
    "if len(mr_array.shape) == 4:\n",
    "    z_size, y_size, x_size, channels = mr_array.shape\n",
    "    crop_bounds = [0, z_size, 0, y_size, 0, x_size]\n",
    "else:\n",
    "    z_size, y_size, x_size = mr_array.shape\n",
    "    crop_bounds = [0, z_size, 0, y_size, 0, x_size]\n",
    "    channels = 1\n",
    "\n",
    "print(f\"📐 Data dimensions: {z_size}×{y_size}×{x_size} with {channels} channels\")\n",
    "print(f\"📋 Crop bounds: {crop_bounds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "379d025b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saving 4-channel MR data: (32, 128, 128, 4)\n",
      "✅ Saved MR data to: ../datasets/all_channels/1HNA001_mr_all_channels.npz\n",
      "✅ Saved CT data to: ../datasets/all_channels/1HNA001_ct.npz\n",
      "\n",
      "🔍 Verification:\n",
      "MR saved shape: (32, 128, 128, 4)\n",
      "CT saved shape: (32, 128, 128)\n",
      "MR channels available: 4\n"
     ]
    }
   ],
   "source": [
    "# Save 4-channel MR data\n",
    "mr_filename = \"1HNA001_mr_all_channels.npz\"\n",
    "mr_output_path = os.path.join(output_dir, mr_filename)\n",
    "\n",
    "# Ensure we have 4D data (D, H, W, C)\n",
    "if len(mr_array.shape) == 4:\n",
    "    # Already has channels\n",
    "    mr_data_to_save = mr_array\n",
    "    print(f\"💾 Saving 4-channel MR data: {mr_array.shape}\")\n",
    "elif len(mr_array.shape) == 3:\n",
    "    # Add channel dimension - but this means we don't have 4 channels\n",
    "    mr_data_to_save = mr_array[..., np.newaxis]\n",
    "    print(f\"⚠️ Only 3D data available, adding single channel: {mr_data_to_save.shape}\")\n",
    "\n",
    "np.savez_compressed(mr_output_path, data=mr_data_to_save)\n",
    "print(f\"✅ Saved MR data to: {mr_output_path}\")\n",
    "\n",
    "# Save CT data\n",
    "ct_filename = \"1HNA001_ct.npz\"\n",
    "ct_output_path = os.path.join(output_dir, ct_filename)\n",
    "\n",
    "np.savez_compressed(ct_output_path, data=ct_array)\n",
    "print(f\"✅ Saved CT data to: {ct_output_path}\")\n",
    "\n",
    "# Verify saved data\n",
    "mr_loaded = np.load(mr_output_path)['data']\n",
    "ct_loaded = np.load(ct_output_path)['data']\n",
    "\n",
    "print(f\"\\n🔍 Verification:\")\n",
    "print(f\"MR saved shape: {mr_loaded.shape}\")\n",
    "print(f\"CT saved shape: {ct_loaded.shape}\")\n",
    "print(f\"MR channels available: {mr_loaded.shape[-1] if len(mr_loaded.shape) == 4 else 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbdaf73",
   "metadata": {},
   "source": [
    "## 📋 Create Dataset Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52dd74b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved dataset metadata to: ../datasets/all_channels/crops.pkl\n",
      "📊 Sample data: {'name': '1HNA001', 'mr_path': '1HNA001_mr_all_channels.npz', 'ct_path': '1HNA001_ct.npz', 'bounds': [0, 32, 0, 128, 0, 128], 'channels': 'all_4_channels', 'channel_count': 4}\n",
      "\n",
      "🔍 Verification - loaded 1 samples:\n",
      "Sample 0: {'name': '1HNA001', 'mr_path': '1HNA001_mr_all_channels.npz', 'ct_path': '1HNA001_ct.npz', 'bounds': [0, 32, 0, 128, 0, 128], 'channels': 'all_4_channels', 'channel_count': 4}\n"
     ]
    }
   ],
   "source": [
    "# Create the crops.pkl file for the dataset\n",
    "sample_data = {\n",
    "    'name': '1HNA001',\n",
    "    'mr_path': mr_filename,\n",
    "    'ct_path': ct_filename,\n",
    "    'bounds': crop_bounds,\n",
    "    'channels': 'all_4_channels',\n",
    "    'channel_count': mr_loaded.shape[-1] if len(mr_loaded.shape) == 4 else 1\n",
    "}\n",
    "\n",
    "samples_list = [sample_data]\n",
    "\n",
    "# Save the metadata\n",
    "crops_pkl_path = os.path.join(output_dir, \"crops.pkl\")\n",
    "with open(crops_pkl_path, 'wb') as f:\n",
    "    pickle.dump(samples_list, f)\n",
    "\n",
    "print(f\"✅ Saved dataset metadata to: {crops_pkl_path}\")\n",
    "print(f\"📊 Sample data: {sample_data}\")\n",
    "\n",
    "# Verify the pickle file\n",
    "with open(crops_pkl_path, 'rb') as f:\n",
    "    loaded_samples = pickle.load(f)\n",
    "    \n",
    "print(f\"\\n🔍 Verification - loaded {len(loaded_samples)} samples:\")\n",
    "for i, sample in enumerate(loaded_samples):\n",
    "    print(f\"Sample {i}: {sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b164ad96",
   "metadata": {},
   "source": [
    "## 🚀 Ready for 4-Channel Training!\n",
    "\n",
    "Your 4-channel dataset is now ready for training with the new `networks_3d_4channel.py`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6065411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training command for 4-channel model\n",
    "print(\"🎯 Training Commands for 4-Channel Model:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Basic training command\n",
    "basic_cmd = f\"\"\"\n",
    "# Basic 4-channel training:\n",
    "python ../launch_4channel_training.py \\\\\n",
    "    --name 4channel_mr_to_ct \\\\\n",
    "    --dataroot {output_dir} \\\\\n",
    "    --architecture unet_4channel_128 \\\\\n",
    "    --batch_size 1 \\\\\n",
    "    --lr 0.0002 \\\\\n",
    "    --niter 50 \\\\\n",
    "    --niter_decay 50 \\\\\n",
    "    --gpu_ids 0\n",
    "\"\"\"\n",
    "\n",
    "# Advanced training command\n",
    "advanced_cmd = f\"\"\"\n",
    "# Advanced 4-channel training with augmentation:\n",
    "python ../launch_4channel_training.py \\\\\n",
    "    --name 4channel_mr_to_ct_advanced \\\\\n",
    "    --dataroot {output_dir} \\\\\n",
    "    --architecture resnet_4channel_6blocks \\\\\n",
    "    --batch_size 2 \\\\\n",
    "    --lr 0.0001 \\\\\n",
    "    --niter 100 \\\\\n",
    "    --niter_decay 100 \\\\\n",
    "    --augment \\\\\n",
    "    --normalize \\\\\n",
    "    --mixed_precision \\\\\n",
    "    --gpu_ids 0\n",
    "\"\"\"\n",
    "\n",
    "print(basic_cmd)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(advanced_cmd)\n",
    "\n",
    "print(\"\\n📁 Files Created for 4-Channel Training:\")\n",
    "files_created = [\n",
    "    \"../models/networks_3d_4channel.py\",\n",
    "    \"../train_4channel.py\", \n",
    "    \"../data/four_channel_dataset.py\",\n",
    "    \"../options/four_channel_train_options.py\",\n",
    "    \"../launch_4channel_training.py\"\n",
    "]\n",
    "\n",
    "for file_path in files_created:\n",
    "    full_path = os.path.abspath(file_path)\n",
    "    exists = \"✅\" if os.path.exists(full_path) else \"❌\"\n",
    "    print(f\"   {exists} {file_path}\")\n",
    "\n",
    "print(f\"\\n📊 Dataset Summary:\")\n",
    "print(f\"   Location: {output_dir}\")\n",
    "print(f\"   Samples: {len(samples_list)}\")\n",
    "print(f\"   MR channels: {mr_loaded.shape[-1] if len(mr_loaded.shape) == 4 else 1}\")\n",
    "print(f\"   MR shape: {mr_loaded.shape}\")\n",
    "print(f\"   CT shape: {ct_loaded.shape}\")\n",
    "\n",
    "print(f\"\\n🎯 Next Steps:\")\n",
    "print(f\"   1. Navigate to the 3D directory: cd ..\")\n",
    "print(f\"   2. Run training with: python launch_4channel_training.py\")\n",
    "print(f\"   3. Monitor training: tensorboard --logdir checkpoints/\")\n",
    "print(f\"   4. Use trained model for inference with test_npz.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
